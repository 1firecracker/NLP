"""
GSM8K Baseline ä¸»æ‰§è¡Œè„šæœ¬
"""
import os
import sys
import json
import argparse
import time
import asyncio
from typing import List, Dict, Any
from pathlib import Path

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from data.config import config
from core.llm_client import LLMClient, token_tracker
from core.baseline import nshot_chats
from core.evaluation import extract_ans_from_response
from processing.concurrent_processor import ConcurrentProcessor
from analysis.method_comparator import MethodComparator, MethodResult

class BaselineRunner:
    """Baselineæ‰§è¡Œå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ‰§è¡Œå™¨"""
        self.client = LLMClient()
        self.results = []
        
    def load_test_data(self, file_path: str) -> List[Dict[str, Any]]:
        """
        åŠ è½½æµ‹è¯•æ•°æ®
        
        Args:
            file_path: æµ‹è¯•æ–‡ä»¶è·¯å¾„
            
        Returns:
            List[Dict]: æµ‹è¯•æ•°æ®åˆ—è¡¨
        """
        data = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        data.append(json.loads(line.strip()))
            print(f"âœ… æˆåŠŸåŠ è½½ {len(data)} æ¡æµ‹è¯•æ•°æ®")
            return data
        except FileNotFoundError:
            print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return []
        except Exception as e:
            print(f"âŒ åŠ è½½æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            return []
    
    def run_zero_shot(self, test_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        è¿è¡ŒZero-shot baseline
        
        Args:
            test_data: æµ‹è¯•æ•°æ®
            
        Returns:
            List[Dict]: ç»“æœåˆ—è¡¨
        """
        print("\nğŸš€ å¼€å§‹Zero-shot baseline...")
        results = []
        
        for i, item in enumerate(test_data):
            if config.VERBOSE:
                print(f"å¤„ç†é—®é¢˜ {i+1}/{len(test_data)}: {item['question'][:50]}...")
            
            # æ„å»ºzero-shot prompt
            messages = nshot_chats(n=0, question=item['question'])
            
            try:
                # è°ƒç”¨API
                response, token_stats = self.client.generate_response(messages)
                token_tracker.add_usage(token_stats)
                
                # æå–ç­”æ¡ˆ
                predicted_answer = extract_ans_from_response(response)
                ground_truth = extract_ans_from_response(item['answer'])
                
                # ä¿å­˜ç»“æœ
                result = {
                    'question': item['question'],
                    'ground_truth': ground_truth,
                    'predicted_answer': predicted_answer,
                    'response': response,
                    'token_stats': token_stats,
                    'correct': predicted_answer == ground_truth
                }
                results.append(result)
                
                if config.VERBOSE:
                    print(f"  é¢„æµ‹ç­”æ¡ˆ: {predicted_answer}, æ­£ç¡®ç­”æ¡ˆ: {ground_truth}, æ­£ç¡®: {result['correct']}")
                    
            except Exception as e:
                print(f"âŒ å¤„ç†é—®é¢˜ {i+1} æ—¶å‡ºé”™: {e}")
                results.append({
                    'question': item['question'],
                    'ground_truth': extract_ans_from_response(item['answer']),
                    'predicted_answer': None,
                    'response': None,
                    'token_stats': None,
                    'correct': False,
                    'error': str(e)
                })
        
        print(f"âœ… Zero-shot baselineå®Œæˆï¼Œå¤„ç†äº† {len(results)} ä¸ªé—®é¢˜")
        return results
    
    def run_few_shot(self, test_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        è¿è¡ŒFew-shot baseline
        
        Args:
            test_data: æµ‹è¯•æ•°æ®
            
        Returns:
            List[Dict]: ç»“æœåˆ—è¡¨
        """
        print("\nğŸš€ å¼€å§‹Few-shot baseline...")
        results = []
        
        for i, item in enumerate(test_data):
            if config.VERBOSE:
                print(f"å¤„ç†é—®é¢˜ {i+1}/{len(test_data)}: {item['question'][:50]}...")
            
            # æ„å»ºfew-shot prompt (ä½¿ç”¨8ä¸ªç¤ºä¾‹)
            messages = nshot_chats(n=8, question=item['question'])
            
            try:
                # è°ƒç”¨API
                response, token_stats = self.client.generate_response(messages)
                token_tracker.add_usage(token_stats)
                
                # æå–ç­”æ¡ˆ
                predicted_answer = extract_ans_from_response(response)
                ground_truth = extract_ans_from_response(item['answer'])
                
                # ä¿å­˜ç»“æœ
                result = {
                    'question': item['question'],
                    'ground_truth': ground_truth,
                    'predicted_answer': predicted_answer,
                    'response': response,
                    'token_stats': token_stats,
                    'correct': predicted_answer == ground_truth
                }
                results.append(result)
                
                if config.VERBOSE:
                    print(f"  é¢„æµ‹ç­”æ¡ˆ: {predicted_answer}, æ­£ç¡®ç­”æ¡ˆ: {ground_truth}, æ­£ç¡®: {result['correct']}")
                    
            except Exception as e:
                print(f"âŒ å¤„ç†é—®é¢˜ {i+1} æ—¶å‡ºé”™: {e}")
                results.append({
                    'question': item['question'],
                    'ground_truth': extract_ans_from_response(item['answer']),
                    'predicted_answer': None,
                    'response': None,
                    'token_stats': None,
                    'correct': False,
                    'error': str(e)
                })
        
        print(f"âœ… Few-shot baselineå®Œæˆï¼Œå¤„ç†äº† {len(results)} ä¸ªé—®é¢˜")
        return results
    
    async def run_concurrent_baseline(self, test_data: List[Dict[str, Any]], method: str = "zero-shot") -> List[Dict[str, Any]]:
        """
        è¿è¡Œå¹¶å‘baseline
        
        Args:
            test_data: æµ‹è¯•æ•°æ®
            method: å¤„ç†æ–¹æ³•
            
        Returns:
            List[Dict]: ç»“æœåˆ—è¡¨
        """
        print(f"\nğŸš€ å¼€å§‹å¹¶å‘{method} baseline...")
        
        # åˆ›å»ºå¹¶å‘å¤„ç†å™¨
        processor = ConcurrentProcessor(max_concurrent=10, rate_limit=100)
        
        # å¹¶å‘å¤„ç†
        results = await processor.process_batch(test_data, method=method)
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        standard_results = []
        for result in results:
            standard_results.append({
                'question': result.question,
                'ground_truth': result.ground_truth,
                'predicted_answer': result.predicted_answer,
                'response': result.response,
                'token_stats': result.token_stats,
                'correct': result.correct,
                'processing_time': result.processing_time,
                'error': result.error
            })
        
        print(f"âœ… å¹¶å‘{method} baselineå®Œæˆï¼Œå¤„ç†äº† {len(standard_results)} ä¸ªé—®é¢˜")
        return standard_results
    
    
    def save_results(self, results: List[Dict[str, Any]], filename: str):
        """
        ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        
        Args:
            results: ç»“æœåˆ—è¡¨
            filename: è¾“å‡ºæ–‡ä»¶å
        """
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(config.OUTPUT_DIR, exist_ok=True)
        
        file_path = os.path.join(config.OUTPUT_DIR, filename)
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                for result in results:
                    f.write(json.dumps(result, ensure_ascii=False) + '\n')
            print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {file_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def calculate_accuracy(self, results: List[Dict[str, Any]]) -> float:
        """
        è®¡ç®—å‡†ç¡®ç‡
        
        Args:
            results: ç»“æœåˆ—è¡¨
            
        Returns:
            float: å‡†ç¡®ç‡
        """
        correct_count = sum(1 for result in results if result.get('correct', False))
        total_count = len(results)
        accuracy = correct_count / total_count if total_count > 0 else 0.0
        return accuracy

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='GSM8K Baseline Runner')
    parser.add_argument('--test-file', default=config.TEST_FILE, help='æµ‹è¯•æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', default=config.OUTPUT_DIR, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--max-questions', type=int, default=None, help='æœ€å¤§å¤„ç†é—®é¢˜æ•°é‡')
    parser.add_argument('--method', choices=['zero-shot', 'few-shot', 'concurrent', 'all'], default='both', help='è¿è¡Œçš„æ–¹æ³•')
    parser.add_argument('--verbose', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    # æ›´æ–°é…ç½®
    config.TEST_FILE = args.test_file
    config.OUTPUT_DIR = args.output_dir
    config.VERBOSE = args.verbose
    
    print("ğŸ¯ GSM8K Baseline å¼€å§‹æ‰§è¡Œ")
    print("=" * 50)
    
    # éªŒè¯é…ç½®
    if not config.validate():
        print("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥è®¾ç½®")
        return
    
    # æ‰“å°é…ç½®
    config.print_config()
    
    # æµ‹è¯•APIè¿æ¥
    runner = BaselineRunner()
    if not runner.client.test_connection():
        print("âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’ŒAPIå¯†é’¥")
        return
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_data = runner.load_test_data(config.TEST_FILE)
    if not test_data:
        print("âŒ æ— æ³•åŠ è½½æµ‹è¯•æ•°æ®")
        return
    
    # é™åˆ¶å¤„ç†æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    if args.max_questions:
        test_data = test_data[:args.max_questions]
        print(f"ğŸ”¬ æµ‹è¯•æ¨¡å¼ï¼šä»…å¤„ç†å‰ {len(test_data)} ä¸ªé—®é¢˜")
    
    # è¿è¡Œbaseline
    if args.method in ['zero-shot', 'both', 'all']:
        zero_shot_results = runner.run_zero_shot(test_data)
        runner.save_results(zero_shot_results, 'zeroshot.baseline.jsonl')
        
        accuracy = runner.calculate_accuracy(zero_shot_results)
        print(f"ğŸ“Š Zero-shot å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    if args.method in ['few-shot', 'both', 'all']:
        few_shot_results = runner.run_few_shot(test_data)
        runner.save_results(few_shot_results, 'fewshot.baseline.jsonl')
        
        accuracy = runner.calculate_accuracy(few_shot_results)
        print(f"ğŸ“Š Few-shot å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    
    if args.method in ['concurrent', 'all']:
        print("ğŸš€ å¼€å§‹å¹¶å‘å¤„ç†...")
        concurrent_results = asyncio.run(runner.run_concurrent_baseline(test_data, "zero-shot"))
        runner.save_results(concurrent_results, 'concurrent.baseline.jsonl')
        
        accuracy = runner.calculate_accuracy(concurrent_results)
        print(f"ğŸ“Š å¹¶å‘Zero-shot å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # æ‰“å°tokenä½¿ç”¨ç»Ÿè®¡
    token_tracker.print_summary()
    
    print("\nğŸ‰ Baselineæ‰§è¡Œå®Œæˆï¼")

if __name__ == "__main__":
    main()
